{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T11:30:12.892375Z","iopub.execute_input":"2021-08-03T11:30:12.892831Z","iopub.status.idle":"2021-08-03T11:30:12.911869Z","shell.execute_reply.started":"2021-08-03T11:30:12.892741Z","shell.execute_reply":"2021-08-03T11:30:12.910843Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/software-classification/train.csv\n/kaggle/input/software-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom transformers import (AutoModel,AutoModelForMaskedLM, AutoTokenizer, LineByLineTextDataset,\n                         DataCollatorForLanguageModeling,Trainer, TrainingArguments,)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:13.382461Z","iopub.execute_input":"2021-08-03T11:30:13.382837Z","iopub.status.idle":"2021-08-03T11:30:16.974302Z","shell.execute_reply.started":"2021-08-03T11:30:13.382805Z","shell.execute_reply":"2021-08-03T11:30:16.973334Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/software-classification/train.csv')\ntest_data = pd.read_csv('../input/software-classification/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:16.975948Z","iopub.execute_input":"2021-08-03T11:30:16.976316Z","iopub.status.idle":"2021-08-03T11:30:16.994154Z","shell.execute_reply.started":"2021-08-03T11:30:16.976277Z","shell.execute_reply":"2021-08-03T11:30:16.993362Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data.subcategory.unique()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:16.996224Z","iopub.execute_input":"2021-08-03T11:30:16.996497Z","iopub.status.idle":"2021-08-03T11:30:17.007230Z","shell.execute_reply.started":"2021-08-03T11:30:16.996457Z","shell.execute_reply":"2021-08-03T11:30:17.006336Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['EMEA_SAP BW/BO', 'EMEA_PL-Local Server', 'EMEA_eSpace',\n       'EMEA_FR-GC-Mix', 'EMEA_SAP MAN'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"category = ['EMEA_PL-Local Server', 'EMEA_eSpace', 'EMEA_SAP MAN']","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:17.266896Z","iopub.execute_input":"2021-08-03T11:30:17.267258Z","iopub.status.idle":"2021-08-03T11:30:17.272522Z","shell.execute_reply.started":"2021-08-03T11:30:17.267214Z","shell.execute_reply":"2021-08-03T11:30:17.271516Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data = train_data[train_data.subcategory.isin(category)]\ntest_data = test_data[test_data.subcategory.isin(category)]\ntest_data.reset_index(drop=True,inplace=True)\ntrain_data.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:20.596891Z","iopub.execute_input":"2021-08-03T11:30:20.597237Z","iopub.status.idle":"2021-08-03T11:30:20.604441Z","shell.execute_reply.started":"2021-08-03T11:30:20.597205Z","shell.execute_reply":"2021-08-03T11:30:20.603429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:21.842038Z","iopub.execute_input":"2021-08-03T11:30:21.842428Z","iopub.status.idle":"2021-08-03T11:30:21.861672Z","shell.execute_reply.started":"2021-08-03T11:30:21.842391Z","shell.execute_reply":"2021-08-03T11:30:21.860294Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory\n0                                                proxy  EMEA_PL-Local Server\n1    mails sent to oneservice service now com are f...           EMEA_eSpace\n2                     damaged cable charging xperia xz  EMEA_PL-Local Server\n3    this issue is related to authorizations hello ...           EMEA_eSpace\n4                   leave request section doesn t work           EMEA_eSpace\n..                                                 ...                   ...\n505  issue hardware software connection launch aure...  EMEA_PL-Local Server\n506           user lcorosov can t access espace portal           EMEA_eSpace\n507  user has critical error trying to access vacat...           EMEA_eSpace\n508                      issue aktywacja karty dla cok  EMEA_PL-Local Server\n509  ess leave request not working in at least coun...           EMEA_eSpace\n\n[510 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>proxy</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mails sent to oneservice service now com are f...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>damaged cable charging xperia xz</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this issue is related to authorizations hello ...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leave request section doesn t work</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>issue hardware software connection launch aure...</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>user lcorosov can t access espace portal</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>user has critical error trying to access vacat...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>issue aktywacja karty dla cok</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>ess leave request not working in at least coun...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n  </tbody>\n</table>\n<p>510 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:21.866991Z","iopub.execute_input":"2021-08-03T11:30:21.867448Z","iopub.status.idle":"2021-08-03T11:30:21.880616Z","shell.execute_reply.started":"2021-08-03T11:30:21.867388Z","shell.execute_reply":"2021-08-03T11:30:21.879340Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory\n0                                                proxy  EMEA_PL-Local Server\n1    mails sent to oneservice service now com are f...           EMEA_eSpace\n2                     damaged cable charging xperia xz  EMEA_PL-Local Server\n3    this issue is related to authorizations hello ...           EMEA_eSpace\n4                   leave request section doesn t work           EMEA_eSpace\n..                                                 ...                   ...\n505  issue hardware software connection launch aure...  EMEA_PL-Local Server\n506           user lcorosov can t access espace portal           EMEA_eSpace\n507  user has critical error trying to access vacat...           EMEA_eSpace\n508                      issue aktywacja karty dla cok  EMEA_PL-Local Server\n509  ess leave request not working in at least coun...           EMEA_eSpace\n\n[510 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>proxy</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mails sent to oneservice service now com are f...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>damaged cable charging xperia xz</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this issue is related to authorizations hello ...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leave request section doesn t work</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>issue hardware software connection launch aure...</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>user lcorosov can t access espace portal</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>user has critical error trying to access vacat...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>issue aktywacja karty dla cok</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>ess leave request not working in at least coun...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n  </tbody>\n</table>\n<p>510 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"text  = '\\n'.join(train_data.text.tolist() + test_data.text.tolist())\n\nwith open('text.txt','w') as f:\n    f.write(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'roberta-large'\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"./text.txt\", #mention text file here\n    block_size=128,\n)\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./Output_DIR\", #select model path\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    eval_steps=20,\n    metric_for_best_model = 'eval_loss',\n    greater_is_better=False,\n    load_best_model_at_end =True,\n    prediction_loss_only=True,\n    report_to = \"none\" \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model('./Output_DIR')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Roberta + SVM: https://www.kaggle.com/maunish/clrp-roberta-svm\nimport os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel, AutoTokenizer,\n                          get_linear_schedule_with_warmup,\n                          get_cosine_schedule_with_warmup)\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:34.776662Z","iopub.execute_input":"2021-08-03T11:30:34.777017Z","iopub.status.idle":"2021-08-03T11:30:34.866531Z","shell.execute_reply.started":"2021-08-03T11:30:34.776983Z","shell.execute_reply":"2021-08-03T11:30:34.865728Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:35.206834Z","iopub.execute_input":"2021-08-03T11:30:35.207187Z","iopub.status.idle":"2021-08-03T11:30:35.218571Z","shell.execute_reply.started":"2021-08-03T11:30:35.207154Z","shell.execute_reply":"2021-08-03T11:30:35.217677Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory\n0                                                proxy  EMEA_PL-Local Server\n1    mails sent to oneservice service now com are f...           EMEA_eSpace\n2                     damaged cable charging xperia xz  EMEA_PL-Local Server\n3    this issue is related to authorizations hello ...           EMEA_eSpace\n4                   leave request section doesn t work           EMEA_eSpace\n..                                                 ...                   ...\n505  issue hardware software connection launch aure...  EMEA_PL-Local Server\n506           user lcorosov can t access espace portal           EMEA_eSpace\n507  user has critical error trying to access vacat...           EMEA_eSpace\n508                      issue aktywacja karty dla cok  EMEA_PL-Local Server\n509  ess leave request not working in at least coun...           EMEA_eSpace\n\n[510 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>proxy</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mails sent to oneservice service now com are f...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>damaged cable charging xperia xz</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this issue is related to authorizations hello ...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leave request section doesn t work</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>issue hardware software connection launch aure...</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>user lcorosov can t access espace portal</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>user has critical error trying to access vacat...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>issue aktywacja karty dla cok</td>\n      <td>EMEA_PL-Local Server</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>ess leave request not working in at least coun...</td>\n      <td>EMEA_eSpace</td>\n    </tr>\n  </tbody>\n</table>\n<p>510 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(train_data['subcategory'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:35.731936Z","iopub.execute_input":"2021-08-03T11:30:35.732268Z","iopub.status.idle":"2021-08-03T11:30:35.740639Z","shell.execute_reply.started":"2021-08-03T11:30:35.732239Z","shell.execute_reply":"2021-08-03T11:30:35.739410Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"LabelEncoder()"},"metadata":{}}]},{"cell_type":"code","source":"le.classes_","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:36.613377Z","iopub.execute_input":"2021-08-03T11:30:36.613774Z","iopub.status.idle":"2021-08-03T11:30:36.620618Z","shell.execute_reply.started":"2021-08-03T11:30:36.613732Z","shell.execute_reply":"2021-08-03T11:30:36.619585Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['EMEA_PL-Local Server', 'EMEA_SAP MAN', 'EMEA_eSpace'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"encoded_label_train = le.transform(train_data['subcategory'])\nencoded_label_test = le.transform(test_data['subcategory'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:37.094822Z","iopub.execute_input":"2021-08-03T11:30:37.095157Z","iopub.status.idle":"2021-08-03T11:30:37.100333Z","shell.execute_reply.started":"2021-08-03T11:30:37.095127Z","shell.execute_reply":"2021-08-03T11:30:37.099097Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data['target'] = encoded_label_train\ntest_data['target']  = encoded_label_test","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:37.493521Z","iopub.execute_input":"2021-08-03T11:30:37.493897Z","iopub.status.idle":"2021-08-03T11:30:37.499284Z","shell.execute_reply.started":"2021-08-03T11:30:37.493864Z","shell.execute_reply":"2021-08-03T11:30:37.498193Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:38.258366Z","iopub.execute_input":"2021-08-03T11:30:38.258794Z","iopub.status.idle":"2021-08-03T11:30:38.274186Z","shell.execute_reply.started":"2021-08-03T11:30:38.258756Z","shell.execute_reply":"2021-08-03T11:30:38.273182Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory  \\\n0                                                proxy  EMEA_PL-Local Server   \n1    mails sent to oneservice service now com are f...           EMEA_eSpace   \n2                     damaged cable charging xperia xz  EMEA_PL-Local Server   \n3    this issue is related to authorizations hello ...           EMEA_eSpace   \n4                   leave request section doesn t work           EMEA_eSpace   \n..                                                 ...                   ...   \n505  issue hardware software connection launch aure...  EMEA_PL-Local Server   \n506           user lcorosov can t access espace portal           EMEA_eSpace   \n507  user has critical error trying to access vacat...           EMEA_eSpace   \n508                      issue aktywacja karty dla cok  EMEA_PL-Local Server   \n509  ess leave request not working in at least coun...           EMEA_eSpace   \n\n     target  \n0         0  \n1         2  \n2         0  \n3         2  \n4         2  \n..      ...  \n505       0  \n506       2  \n507       2  \n508       0  \n509       2  \n\n[510 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>proxy</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mails sent to oneservice service now com are f...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>damaged cable charging xperia xz</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this issue is related to authorizations hello ...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leave request section doesn t work</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>issue hardware software connection launch aure...</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>user lcorosov can t access espace portal</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>user has critical error trying to access vacat...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>issue aktywacja karty dla cok</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>ess leave request not working in at least coun...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>510 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = train_data\ntest_data = test_data\n\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\nbins = train_data.bins.to_numpy()\ntarget = train_data.target.to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:38.784413Z","iopub.execute_input":"2021-08-03T11:30:38.784800Z","iopub.status.idle":"2021-08-03T11:30:38.792760Z","shell.execute_reply.started":"2021-08-03T11:30:38.784763Z","shell.execute_reply":"2021-08-03T11:30:38.791878Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"config = {\n    'lr': 2e-5,\n    'wd':0.01,\n    'batch_size':16,\n    'valid_step':10,\n    'max_len':200,\n    'epochs':3,\n    'nfolds':5,\n    'seed':42,\n}\n\nfor i in range(config['nfolds']):\n    os.makedirs(f'model{i}',exist_ok=True)\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])\n\ntrain_data['Fold'] = -1\nkfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\nfor k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=bins)):\n    train_data.loc[valid_idx,'Fold'] = k\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:39.493402Z","iopub.execute_input":"2021-08-03T11:30:39.493894Z","iopub.status.idle":"2021-08-03T11:30:39.510495Z","shell.execute_reply.started":"2021-08-03T11:30:39.493854Z","shell.execute_reply":"2021-08-03T11:30:39.509714Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['text'].to_numpy()\n        self.targets = df['target'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        \n        target = torch.tensor(self.targets[idx],dtype=torch.long) \n        return encode, target\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:40.652457Z","iopub.execute_input":"2021-08-03T11:30:40.652811Z","iopub.status.idle":"2021-08-03T11:30:40.659272Z","shell.execute_reply.started":"2021-08-03T11:30:40.652776Z","shell.execute_reply":"2021-08-03T11:30:40.658405Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 3)\n#         self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n#         attention_weights = torch.softmax(score, dim=1)\n\n#         context_vector = attention_weights * features\n#         context_vector = torch.sum(context_vector, dim=1)\n\n#         return context_vector\n        return score\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:41.153152Z","iopub.execute_input":"2021-08-03T11:30:41.153505Z","iopub.status.idle":"2021-08-03T11:30:41.159094Z","shell.execute_reply.started":"2021-08-03T11:30:41.153471Z","shell.execute_reply":"2021-08-03T11:30:41.158253Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,path):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained(path)  \n        self.head = AttentionHead(1024,1024)\n#         self.dropout = nn.Dropout(0.1)\n#         self.softmax = nn.Softmax(3)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n#         x = self.dropout(x)\n#         x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:41.783785Z","iopub.execute_input":"2021-08-03T11:30:41.784184Z","iopub.status.idle":"2021-08-03T11:30:41.790796Z","shell.execute_reply.started":"2021-08-03T11:30:41.784153Z","shell.execute_reply":"2021-08-03T11:30:41.789536Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"x_train,x_valid = train_data.query(f\"Fold != 0\"),train_data.query(f\"Fold == 0\")\nprint(x_train.shape)\nprint(x_valid.shape)\nMODEL_PATH = './Output_DIR'\ntokenizer = AutoTokenizer.from_pretrained('roberta-large')\n\n\ntrain_ds = CLRPDataset(x_train,tokenizer,config['max_len'])\ntrain_dl = DataLoader(train_ds,\n                    batch_size = config[\"batch_size\"],\n                    shuffle=True,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n\nvalid_ds = CLRPDataset(x_valid,tokenizer,config['max_len'])\nvalid_dl = DataLoader(valid_ds,\n                    batch_size = config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:42.512079Z","iopub.execute_input":"2021-08-03T11:30:42.512416Z","iopub.status.idle":"2021-08-03T11:30:45.697124Z","shell.execute_reply.started":"2021-08-03T11:30:42.512383Z","shell.execute_reply":"2021-08-03T11:30:45.696108Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"(408, 5)\n(102, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:45.698804Z","iopub.execute_input":"2021-08-03T11:30:45.699175Z","iopub.status.idle":"2021-08-03T11:30:45.715706Z","shell.execute_reply.started":"2021-08-03T11:30:45.699136Z","shell.execute_reply":"2021-08-03T11:30:45.714494Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory  \\\n0                                                proxy  EMEA_PL-Local Server   \n1    mails sent to oneservice service now com are f...           EMEA_eSpace   \n2                     damaged cable charging xperia xz  EMEA_PL-Local Server   \n3    this issue is related to authorizations hello ...           EMEA_eSpace   \n4                   leave request section doesn t work           EMEA_eSpace   \n..                                                 ...                   ...   \n504  can t logon to sap after migration to windows ...          EMEA_SAP MAN   \n505  issue hardware software connection launch aure...  EMEA_PL-Local Server   \n507  user has critical error trying to access vacat...           EMEA_eSpace   \n508                      issue aktywacja karty dla cok  EMEA_PL-Local Server   \n509  ess leave request not working in at least coun...           EMEA_eSpace   \n\n     target  bins  Fold  \n0         0     0     4  \n1         2     8     4  \n2         0     0     1  \n3         2     8     3  \n4         2     8     2  \n..      ...   ...   ...  \n504       1     4     1  \n505       0     0     2  \n507       2     8     3  \n508       0     0     2  \n509       2     8     3  \n\n[408 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n      <th>target</th>\n      <th>bins</th>\n      <th>Fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>proxy</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mails sent to oneservice service now com are f...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>damaged cable charging xperia xz</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this issue is related to authorizations hello ...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leave request section doesn t work</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>can t logon to sap after migration to windows ...</td>\n      <td>EMEA_SAP MAN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>issue hardware software connection launch aure...</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>user has critical error trying to access vacat...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>issue aktywacja karty dla cok</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>ess leave request not working in at least coun...</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>408 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_valid","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:45.718109Z","iopub.execute_input":"2021-08-03T11:30:45.718679Z","iopub.status.idle":"2021-08-03T11:30:45.734249Z","shell.execute_reply.started":"2021-08-03T11:30:45.718597Z","shell.execute_reply":"2021-08-03T11:30:45.733334Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                  text           subcategory  \\\n5                ess leave requst incorrect supervisor           EMEA_eSpace   \n7              work oder list has no work oders at all          EMEA_SAP MAN   \n24               request separate bazalt dolomit rooms  EMEA_PL-Local Server   \n25                     user unable to access their ess           EMEA_eSpace   \n36                                         in approval          EMEA_SAP MAN   \n..                                                 ...                   ...   \n491  management decided to transfer maintenance of ...          EMEA_SAP MAN   \n493  capacity displayed in shift updater is differe...          EMEA_SAP MAN   \n495                          add permissions directory  EMEA_PL-Local Server   \n503                       problem mail operation phone  EMEA_PL-Local Server   \n506           user lcorosov can t access espace portal           EMEA_eSpace   \n\n     target  bins  Fold  \n5         2     8     0  \n7         1     4     0  \n24        0     0     0  \n25        2     8     0  \n36        1     4     0  \n..      ...   ...   ...  \n491       1     4     0  \n493       1     4     0  \n495       0     0     0  \n503       0     0     0  \n506       2     8     0  \n\n[102 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>subcategory</th>\n      <th>target</th>\n      <th>bins</th>\n      <th>Fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>ess leave requst incorrect supervisor</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>work oder list has no work oders at all</td>\n      <td>EMEA_SAP MAN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>request separate bazalt dolomit rooms</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>user unable to access their ess</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>in approval</td>\n      <td>EMEA_SAP MAN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>management decided to transfer maintenance of ...</td>\n      <td>EMEA_SAP MAN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>capacity displayed in shift updater is differe...</td>\n      <td>EMEA_SAP MAN</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>add permissions directory</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>problem mail operation phone</td>\n      <td>EMEA_PL-Local Server</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>user lcorosov can t access espace portal</td>\n      <td>EMEA_eSpace</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(test_data.shape)\ntest_ds = CLRPDataset(test_data,tokenizer,config['max_len'])\ntest_dl = DataLoader(test_ds,\n                    batch_size = config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:45.735773Z","iopub.execute_input":"2021-08-03T11:30:45.736288Z","iopub.status.idle":"2021-08-03T11:30:45.744162Z","shell.execute_reply.started":"2021-08-03T11:30:45.736217Z","shell.execute_reply":"2021-08-03T11:30:45.743012Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(510, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:46.736516Z","iopub.execute_input":"2021-08-03T11:30:46.736878Z","iopub.status.idle":"2021-08-03T11:30:46.744017Z","shell.execute_reply.started":"2021-08-03T11:30:46.736847Z","shell.execute_reply":"2021-08-03T11:30:46.743078Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(510, 5)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"./Output_DIR\", num_labels=3)\n\n\nfrom transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n\nfrom transformers import get_scheduler\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dl)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)\n\nimport torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:47.057359Z","iopub.execute_input":"2021-08-03T11:30:47.057751Z","iopub.status.idle":"2021-08-03T11:30:54.325251Z","shell.execute_reply.started":"2021-08-03T11:30:47.057713Z","shell.execute_reply":"2021-08-03T11:30:54.324289Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ./Output_DIR were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./Output_DIR and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (12): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (13): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (14): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (15): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (16): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (17): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (18): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (19): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (20): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (21): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (22): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (23): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:54.326888Z","iopub.execute_input":"2021-08-03T11:30:54.327298Z","iopub.status.idle":"2021-08-03T11:30:54.331421Z","shell.execute_reply.started":"2021-08-03T11:30:54.327255Z","shell.execute_reply":"2021-08-03T11:30:54.330324Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch,labels in train_dl:\n#         print(batch)\n#         print(labels)\n#         batch = {k: v.to(device) for k, v in batch.items()}\n        batch = {key:val.reshape(val.shape[0],-1).to(device) for key,val in batch.items()}\n#         print(batch)\n        outputs = model(**batch)\n        \n#         print(outputs[0])\n#         print(labels)\n        loss = nn.CrossEntropyLoss()(outputs[0].to(device),labels.to(device))\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:30:54.334152Z","iopub.execute_input":"2021-08-03T11:30:54.334653Z","iopub.status.idle":"2021-08-03T11:32:13.251646Z","shell.execute_reply.started":"2021-08-03T11:30:54.334608Z","shell.execute_reply":"2021-08-03T11:32:13.250710Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ca8fb9cd6f417d8da19d55892b62c0"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric       \n\nmetric= load_metric(\"accuracy\")\nmodel.eval()\nfor batch,labels in valid_dl:\n#     batch = {k: v.to(device) for k, v in batch.items()}\n    batch = {key:val.reshape(val.shape[0],-1).to(device) for key,val in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=labels)\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:33:16.198380Z","iopub.execute_input":"2021-08-03T11:33:16.198824Z","iopub.status.idle":"2021-08-03T11:33:19.812892Z","shell.execute_reply.started":"2021-08-03T11:33:16.198785Z","shell.execute_reply":"2021-08-03T11:33:19.812040Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d05c937dc614f94b51d7ebe0b0ec5ea"}},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.9411764705882353}"},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:33:30.822694Z","iopub.execute_input":"2021-08-03T11:33:30.823033Z","iopub.status.idle":"2021-08-03T11:33:30.830340Z","shell.execute_reply.started":"2021-08-03T11:33:30.823001Z","shell.execute_reply":"2021-08-03T11:33:30.829395Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 2, 0, 0, 2], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"outputs","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:33:48.232014Z","iopub.execute_input":"2021-08-03T11:33:48.232378Z","iopub.status.idle":"2021-08-03T11:33:48.242396Z","shell.execute_reply.started":"2021-08-03T11:33:48.232344Z","shell.execute_reply":"2021-08-03T11:33:48.240996Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"SequenceClassifierOutput(loss=None, logits=tensor([[-4.9551,  4.7453, -0.2262],\n        [-2.6653,  5.0066, -2.3833],\n        [-4.6228,  1.3558,  2.8627],\n        [ 4.8663, -1.8834, -2.4694],\n        [ 4.9933, -2.5770, -1.8472],\n        [-2.6894, -2.9468,  5.0155]], device='cuda:0'), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"logits","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:33:59.368851Z","iopub.execute_input":"2021-08-03T11:33:59.369188Z","iopub.status.idle":"2021-08-03T11:33:59.378413Z","shell.execute_reply.started":"2021-08-03T11:33:59.369155Z","shell.execute_reply":"2021-08-03T11:33:59.377340Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"tensor([[-4.9551,  4.7453, -0.2262],\n        [-2.6653,  5.0066, -2.3833],\n        [-4.6228,  1.3558,  2.8627],\n        [ 4.8663, -1.8834, -2.4694],\n        [ 4.9933, -2.5770, -1.8472],\n        [-2.6894, -2.9468,  5.0155]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric       \n\nmetric= load_metric(\"accuracy\")\nmodel.eval()\nfor batch,labels in test_dl:\n#     batch = {k: v.to(device) for k, v in batch.items()}\n    batch = {key:val.reshape(val.shape[0],-1).to(device) for key,val in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=labels)\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:34:50.227297Z","iopub.execute_input":"2021-08-03T11:34:50.227657Z","iopub.status.idle":"2021-08-03T11:35:02.889308Z","shell.execute_reply.started":"2021-08-03T11:34:50.227622Z","shell.execute_reply":"2021-08-03T11:35:02.888483Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.984313725490196}"},"metadata":{}}]},{"cell_type":"code","source":"model?","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:35:38.652781Z","iopub.execute_input":"2021-08-03T11:35:38.653139Z","iopub.status.idle":"2021-08-03T11:35:38.716702Z","shell.execute_reply.started":"2021-08-03T11:35:38.653106Z","shell.execute_reply":"2021-08-03T11:35:38.715790Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mType:\u001b[0m           RobertaForSequenceClassification\n\u001b[0;31mString form:\u001b[0m   \nRobertaForSequenceClassification(\n           (roberta): RobertaModel(\n           (embeddings): RobertaEmbeddings( <...> t(p=0.1, inplace=False)\n           (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n           )\n           )\n\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\n\u001b[0;31mDocstring:\u001b[0m     \nRoBERTa Model transformer with a sequence classification/regression head on top (a linear layer on top of the\npooled output) e.g. for GLUE tasks.\n\n\nThis model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\nmethods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\npruning heads etc.)\n\nThis model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__\nsubclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to\ngeneral usage and behavior.\n\nParameters:\n    config (:class:`~transformers.RobertaConfig`): Model configuration class with all the parameters of the\n        model. Initializing with a config file does not load the weights associated with the model, only the\n        configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model\n        weights.\n\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n"},"metadata":{}}]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:44:11.504307Z","iopub.execute_input":"2021-08-03T11:44:11.504736Z","iopub.status.idle":"2021-08-03T11:44:11.511880Z","shell.execute_reply.started":"2021-08-03T11:44:11.504698Z","shell.execute_reply":"2021-08-03T11:44:11.510993Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification"},"metadata":{}}]},{"cell_type":"code","source":"# save the weights of the model to a .pt file\ntorch.save(model.state_dict(), \"./Output_DIR/saved_txt_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:40:50.672466Z","iopub.execute_input":"2021-08-03T11:40:50.672852Z","iopub.status.idle":"2021-08-03T11:40:53.883754Z","shell.execute_reply.started":"2021-08-03T11:40:50.672820Z","shell.execute_reply":"2021-08-03T11:40:53.882676Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"loaded_model = AutoModelForSequenceClassification.from_pretrained(\"./Output_DIR\", num_labels=3)\nloaded_model.load_state_dict(torch.load(\"./Output_DIR/saved_txt_model.pt\"))\n# model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:51:45.092526Z","iopub.execute_input":"2021-08-03T11:51:45.092902Z","iopub.status.idle":"2021-08-03T11:51:50.091969Z","shell.execute_reply.started":"2021-08-03T11:51:45.092870Z","shell.execute_reply":"2021-08-03T11:51:50.090985Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ./Output_DIR were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./Output_DIR and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"loaded_model.eval()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T11:52:54.308696Z","iopub.execute_input":"2021-08-03T11:52:54.309046Z","iopub.status.idle":"2021-08-03T11:52:54.322238Z","shell.execute_reply.started":"2021-08-03T11:52:54.309016Z","shell.execute_reply":"2021-08-03T11:52:54.321368Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (12): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (13): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (14): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (15): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (16): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (17): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (18): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (19): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (20): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (21): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (22): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (23): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"loaded_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T12:10:03.157273Z","iopub.execute_input":"2021-08-03T12:10:03.157648Z","iopub.status.idle":"2021-08-03T12:10:03.542170Z","shell.execute_reply.started":"2021-08-03T12:10:03.157609Z","shell.execute_reply":"2021-08-03T12:10:03.540994Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (12): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (13): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (14): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (15): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (16): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (17): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (18): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (19): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (20): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (21): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (22): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (23): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric       \n\nmetric= load_metric(\"accuracy\")\nloaded_model.eval()\nfor batch,labels in test_dl:\n#     batch = {k: v.to(device) for k, v in batch.items()}\n    batch = {key:val.reshape(val.shape[0],-1).to(device) for key,val in batch.items()}\n    with torch.no_grad():\n        outputs = loaded_model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=labels)\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T12:10:03.892285Z","iopub.execute_input":"2021-08-03T12:10:03.892650Z","iopub.status.idle":"2021-08-03T12:10:15.747424Z","shell.execute_reply.started":"2021-08-03T12:10:03.892614Z","shell.execute_reply":"2021-08-03T12:10:15.746503Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.984313725490196}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}